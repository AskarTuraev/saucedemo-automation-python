"""
AI Code Reviewer
================

AI-powered code review —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞.
"""

import json
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path

from ..test_generation.llm_client import LLMClient, LLMProvider


class ReviewSeverity(Enum):
    """–°–µ—Ä—å–µ–∑–Ω–æ—Å—Ç—å –∑–∞–º–µ—á–∞–Ω–∏—è"""
    CRITICAL = "critical"
    MAJOR = "major"
    MINOR = "minor"
    SUGGESTION = "suggestion"


class ReviewCategory(Enum):
    """–ö–∞—Ç–µ–≥–æ—Ä–∏—è –∑–∞–º–µ—á–∞–Ω–∏—è"""
    BUG = "bug"
    SECURITY = "security"
    PERFORMANCE = "performance"
    BEST_PRACTICES = "best_practices"
    CODE_STYLE = "code_style"
    MAINTAINABILITY = "maintainability"
    TESTING = "testing"
    DOCUMENTATION = "documentation"


@dataclass
class ReviewComment:
    """–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π code review"""
    file: str
    line: int
    severity: ReviewSeverity
    category: ReviewCategory
    message: str
    suggestion: Optional[str] = None
    code_snippet: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "file": self.file,
            "line": self.line,
            "severity": self.severity.value,
            "category": self.category.value,
            "message": self.message,
            "suggestion": self.suggestion,
            "code_snippet": self.code_snippet
        }


@dataclass
class AIReviewResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç AI code review"""
    overall_score: float  # 0-100
    total_comments: int
    critical: int
    major: int
    minor: int
    suggestions: int
    comments: List[ReviewComment] = field(default_factory=list)
    summary: str = ""
    approved: bool = True

    def to_dict(self) -> Dict[str, Any]:
        return {
            "overall_score": self.overall_score,
            "total_comments": self.total_comments,
            "critical": self.critical,
            "major": self.major,
            "minor": self.minor,
            "suggestions": self.suggestions,
            "summary": self.summary,
            "approved": self.approved,
            "comments": [c.to_dict() for c in self.comments]
        }


class AICodeReviewer:
    """
    AI Code Reviewer

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç LLM –¥–ª—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ code review:
    - –ü–æ–∏—Å–∫ –±–∞–≥–æ–≤ –∏ –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫
    - Security vulnerabilities
    - Performance issues
    - Best practices violations
    - Code style improvements
    - Suggestions –¥–ª—è —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞
    """

    def __init__(
        self,
        llm_provider: LLMProvider = LLMProvider.OPENAI,
        model: Optional[str] = None,
        api_key: Optional[str] = None,
        auto_approve_threshold: float = 85.0
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI reviewer

        Args:
            llm_provider: –ü—Ä–æ–≤–∞–π–¥–µ—Ä LLM
            model: –ú–æ–¥–µ–ª—å LLM
            api_key: API –∫–ª—é—á
            auto_approve_threshold: –ü–æ—Ä–æ–≥ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ approve
        """
        self.llm = LLMClient(
            provider=llm_provider,
            model=model,
            api_key=api_key,
            temperature=0.3  # Lower temperature for more consistent reviews
        )
        self.auto_approve_threshold = auto_approve_threshold

    def review_file(
        self,
        file_path: str,
        context: Optional[str] = None
    ) -> AIReviewResult:
        """
        Review –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞

        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (—Ü–µ–ª—å –∫–æ–¥–∞, —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –∏ —Ç.–¥.)

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç review
        """
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
        with open(file_path, 'r', encoding='utf-8') as f:
            code = f.read()

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º prompt –¥–ª—è LLM
        prompt = self._create_review_prompt(
            code=code,
            file_name=Path(file_path).name,
            context=context
        )

        # –ü–æ–ª—É—á–∞–µ–º review –æ—Ç LLM
        try:
            review_data = self.llm.generate_json(prompt)
            return self._parse_review_response(review_data, file_path)
        except Exception as e:
            # Fallback: –±–∞–∑–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
            return AIReviewResult(
                overall_score=50.0,
                total_comments=1,
                critical=0,
                major=1,
                minor=0,
                suggestions=0,
                comments=[ReviewComment(
                    file=file_path,
                    line=0,
                    severity=ReviewSeverity.MAJOR,
                    category=ReviewCategory.BUG,
                    message=f"AI Review failed: {str(e)}"
                )],
                summary="AI review failed",
                approved=False
            )

    def review_directory(
        self,
        directory: str,
        pattern: str = "*.py"
    ) -> AIReviewResult:
        """
        Review –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏

        Args:
            directory: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            pattern: Glob pattern –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤

        Returns:
            –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        """
        dir_path = Path(directory)
        files = list(dir_path.rglob(pattern))

        all_comments = []
        total_score = 0.0

        for file_path in files:
            result = self.review_file(str(file_path))
            all_comments.extend(result.comments)
            total_score += result.overall_score

        avg_score = total_score / len(files) if files else 0.0

        # –ü–æ–¥—Å—á–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –ø–æ severity
        critical = sum(1 for c in all_comments if c.severity == ReviewSeverity.CRITICAL)
        major = sum(1 for c in all_comments if c.severity == ReviewSeverity.MAJOR)
        minor = sum(1 for c in all_comments if c.severity == ReviewSeverity.MINOR)
        suggestions = sum(1 for c in all_comments if c.severity == ReviewSeverity.SUGGESTION)

        return AIReviewResult(
            overall_score=round(avg_score, 1),
            total_comments=len(all_comments),
            critical=critical,
            major=major,
            minor=minor,
            suggestions=suggestions,
            comments=all_comments,
            summary=f"Reviewed {len(files)} files. Average score: {avg_score:.1f}/100",
            approved=(avg_score >= self.auto_approve_threshold and critical == 0)
        )

    def _create_review_prompt(
        self,
        code: str,
        file_name: str,
        context: Optional[str]
    ) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ prompt –¥–ª—è AI code review"""
        prompt = f"""
–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π Senior QA Engineer –∏ Code Reviewer. –ü—Ä–æ–≤–µ–¥–∏ –¥–µ—Ç–∞–ª—å–Ω—ã–π code review —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞.

FILE: {file_name}
{f"CONTEXT: {context}" if context else ""}

CODE:
```python
{code}
```

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–¥ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç:
1. **Bugs & Logic Errors** - –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏, –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –±–∞–≥–∏
2. **Security Vulnerabilities** - SQL injection, XSS, insecure data handling
3. **Performance Issues** - –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã, memory leaks
4. **Best Practices** - –Ω–∞—Ä—É—à–µ–Ω–∏—è Python/Pytest/Playwright best practices
5. **Code Style** - PEP 8, naming conventions, code readability
6. **Maintainability** - —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∫–æ–¥–∞, –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞
7. **Testing** - –∫–∞—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤, –ø–æ–∫—Ä—ã—Ç–∏–µ edge cases
8. **Documentation** - docstrings, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, type hints

–í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
{{
  "overall_score": 85,  // 0-100, –≥–¥–µ 100 = –∏–¥–µ–∞–ª—å–Ω–æ
  "summary": "–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ code review",
  "comments": [
    {{
      "line": 42,
      "severity": "critical|major|minor|suggestion",
      "category": "bug|security|performance|best_practices|code_style|maintainability|testing|documentation",
      "message": "–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã",
      "suggestion": "–ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)",
      "code_snippet": "–ü—Ä–æ–±–ª–µ–º–Ω—ã–π –∫–æ–¥ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"
    }}
  ]
}}

–í–ê–ñ–ù–û:
- –ë—É–¥—å –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ã–º –∏ helpful
- –î–∞–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ suggestions –∫–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å
- –§–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º–∞—Ö, –Ω–µ –ø—Ä–∏–¥–∏—Ä–∞–π—Å—è –∫ –º–µ–ª–æ—á–∞–º
- –î–ª—è —Ç–µ—Å—Ç–æ–≤: –ø—Ä–æ–≤–µ—Ä—è–π –ø–æ–∫—Ä—ã—Ç–∏–µ edge cases, assertions, error handling
- –î–ª—è Playwright: –ø—Ä–æ–≤–µ—Ä—è–π –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å locators, waits, assertions

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON, –±–µ–∑ markdown –±–ª–æ–∫–æ–≤.
"""
        return prompt

    def _parse_review_response(
        self,
        review_data: Dict[str, Any],
        file_path: str
    ) -> AIReviewResult:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM"""
        # –ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
        comments = []
        for comment_data in review_data.get("comments", []):
            try:
                severity = ReviewSeverity(comment_data.get("severity", "minor"))
            except ValueError:
                severity = ReviewSeverity.MINOR

            try:
                category = ReviewCategory(comment_data.get("category", "best_practices"))
            except ValueError:
                category = ReviewCategory.BEST_PRACTICES

            comments.append(ReviewComment(
                file=file_path,
                line=comment_data.get("line", 0),
                severity=severity,
                category=category,
                message=comment_data.get("message", ""),
                suggestion=comment_data.get("suggestion"),
                code_snippet=comment_data.get("code_snippet")
            ))

        # –ü–æ–¥—Å—á–µ—Ç –ø–æ severity
        critical = sum(1 for c in comments if c.severity == ReviewSeverity.CRITICAL)
        major = sum(1 for c in comments if c.severity == ReviewSeverity.MAJOR)
        minor = sum(1 for c in comments if c.severity == ReviewSeverity.MINOR)
        suggestions = sum(1 for c in comments if c.severity == ReviewSeverity.SUGGESTION)

        overall_score = review_data.get("overall_score", 50.0)
        approved = (overall_score >= self.auto_approve_threshold and critical == 0)

        return AIReviewResult(
            overall_score=overall_score,
            total_comments=len(comments),
            critical=critical,
            major=major,
            minor=minor,
            suggestions=suggestions,
            comments=comments,
            summary=review_data.get("summary", ""),
            approved=approved
        )

    def generate_report(
        self,
        result: AIReviewResult,
        output_format: str = "markdown"
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ code review

        Args:
            result: –†–µ–∑—É–ª—å—Ç–∞—Ç review
            output_format: –§–æ—Ä–º–∞—Ç –æ—Ç—á–µ—Ç–∞ (markdown, html, json)

        Returns:
            –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á–µ—Ç
        """
        if output_format == "json":
            return json.dumps(result.to_dict(), indent=2)

        elif output_format == "markdown":
            return self._generate_markdown_report(result)

        elif output_format == "html":
            return self._generate_html_report(result)

        return str(result.to_dict())

    def _generate_markdown_report(self, result: AIReviewResult) -> str:
        """Markdown –æ—Ç—á–µ—Ç"""
        status = "‚úÖ APPROVED" if result.approved else "‚ùå CHANGES REQUESTED"

        report = f"""# AI Code Review Report

## Summary

**Status:** {status}
**Overall Score:** {result.overall_score}/100

**Issues Found:**
- üî¥ Critical: {result.critical}
- üü† Major: {result.major}
- üü° Minor: {result.minor}
- üí° Suggestions: {result.suggestions}
- **Total:** {result.total_comments}

{result.summary}

---

"""

        if result.comments:
            report += "## Detailed Comments\n\n"

            # Group by severity
            for severity in [ReviewSeverity.CRITICAL, ReviewSeverity.MAJOR, ReviewSeverity.MINOR, ReviewSeverity.SUGGESTION]:
                severity_comments = [c for c in result.comments if c.severity == severity]

                if severity_comments:
                    icon = {"critical": "üî¥", "major": "üü†", "minor": "üü°", "suggestion": "üí°"}
                    report += f"### {icon[severity.value]} {severity.value.title()}\n\n"

                    for comment in severity_comments:
                        report += f"**{Path(comment.file).name}:{comment.line}** - `{comment.category.value}`\n\n"
                        report += f"{comment.message}\n\n"

                        if comment.suggestion:
                            report += f"**üí° Suggestion:**\n```python\n{comment.suggestion}\n```\n\n"

                        report += "---\n\n"

        return report

    def _generate_html_report(self, result: AIReviewResult) -> str:
        """HTML –æ—Ç—á–µ—Ç (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)"""
        # TODO: Implement full HTML report with styling
        return f"<html><body><h1>AI Code Review</h1><p>Score: {result.overall_score}</p></body></html>"
