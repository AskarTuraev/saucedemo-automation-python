# ü¶ô Ollama Setup - –ë–µ—Å–ø–ª–∞—Ç–Ω–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ OpenAI

**–ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å AI-Driven QA Pipeline –±–µ–∑ –ø–ª–∞—Ç–Ω—ã—Ö API –∫–ª—é—á–µ–π**

---

## ‚ö° –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –®–∞–≥ 1: –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Ollama (5 –º–∏–Ω—É—Ç)

1. –°–∫–∞—á–∞–π—Ç–µ Ollama –¥–ª—è Windows:
   - https://ollama.ai/download
   - –ò–ª–∏ –ø—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞: https://ollama.ai/download/windows

2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —É—Å—Ç–∞–Ω–æ–≤—â–∏–∫ `OllamaSetup.exe`

3. –î–æ–∂–¥–∏—Ç–µ—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏

### –®–∞–≥ 2: –ó–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å (5-10 –º–∏–Ω—É—Ç)

```powershell
# –û—Ç–∫—Ä–æ–π—Ç–µ –Ω–æ–≤—ã–π PowerShell –∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:
ollama pull llama2
```

**–≠—Ç–æ —Å–∫–∞—á–∞–µ—Ç ~4GB –¥–∞–Ω–Ω—ã—Ö, –ø–æ–¥–æ–∂–¥–∏—Ç–µ –ø–æ–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—Å—è.**

### –®–∞–≥ 3: –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç

```powershell
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤–µ—Ä—Å–∏—é
ollama --version

# –°–ø–∏—Å–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
ollama list

# –î–æ–ª–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å:
# llama2:latest
```

### –®–∞–≥ 4: –ó–∞–ø—É—Å—Ç–∏—Ç–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç–µ—Å—Ç–æ–≤!

```powershell
# –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ venv
.\venv\Scripts\Activate.ps1

# –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å Ollama
python -m ai_qa_pipeline.modules.code_generation.cli full requirements.txt --base-url https://www.saucedemo.com --llm ollama --model llama2 --output generated_tests
```

---

## üéØ –ì–æ—Ç–æ–≤—ã–µ –∫–æ–º–∞–Ω–¥—ã (–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å-–≤—Å—Ç–∞–≤–∏—Ç—å)

### –ü–æ–ª–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å Ollama:

```powershell
# 1. –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å venv
.\venv\Scripts\Activate.ps1

# 2. –°–æ–∑–¥–∞—Ç—å requirements
@"
Feature: User Login
As a user I want to login to SauceDemo
So that I can access the product catalog

Scenario: Successful login
Given I am on the login page
When I enter valid credentials
Then I should see the inventory page
"@ | Out-File -Encoding UTF8 requirements.txt

# 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å Ollama
python -m ai_qa_pipeline.modules.code_generation.cli full requirements.txt --base-url https://www.saucedemo.com --llm ollama --model llama2 --output generated_tests

# 4. –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
cd generated_tests
pytest -v --headed
```

---

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ: OpenAI vs Ollama

| –ü–∞—Ä–∞–º–µ—Ç—Ä | OpenAI GPT-4 | Ollama (llama2) |
|----------|--------------|-----------------|
| **–°—Ç–æ–∏–º–æ—Å—Ç—å** | ~$0.25 –∑–∞ 5 —Ç–µ—Å—Ç–æ–≤ | üÜì –ë–µ—Å–ø–ª–∞—Ç–Ω–æ |
| **–°–∫–æ—Ä–æ—Å—Ç—å** | 30-60 —Å–µ–∫—É–Ω–¥ | 2-5 –º–∏–Ω—É—Ç |
| **–ö–∞—á–µ—Å—Ç–≤–æ** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê –û—Ç–ª–∏—á–Ω–æ | ‚≠ê‚≠ê‚≠ê‚≠ê –•–æ—Ä–æ—à–æ |
| **–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è** | –ò–Ω—Ç–µ—Ä–Ω–µ—Ç + API –∫–ª—é—á | –õ–æ–∫–∞–ª—å–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ |
| **–†–∞–∑–º–µ—Ä** | - | ~4GB –Ω–∞ –¥–∏—Å–∫–µ |
| **–ù–∞—Å—Ç—Ä–æ–π–∫–∞** | 2 –º–∏–Ω—É—Ç—ã (.env) | 10 –º–∏–Ω—É—Ç (—É—Å—Ç–∞–Ω–æ–≤–∫–∞) |

---

## üîÑ –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ Ollama

```powershell
# –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–æ–¥–∞:

# 1. llama2 (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è, 4GB)
ollama pull llama2

# 2. codellama (—Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è –∫–æ–¥–∞, 4GB)
ollama pull codellama

# 3. mistral (–±—ã—Å—Ç—Ä–∞—è –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è, 4GB)
ollama pull mistral

# 4. llama3 (–Ω–æ–≤–µ–π—à–∞—è, 4.7GB) - –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø!
ollama pull llama3
```

### –ö–∞–∫—É—é –º–æ–¥–µ–ª—å –≤—ã–±—Ä–∞—Ç—å?

- **llama2** - —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è, —Ö–æ—Ä–æ—à–∞—è –¥–ª—è –Ω–∞—á–∞–ª–∞
- **llama3** - –Ω–æ–≤–µ–π—à–∞—è, –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è!)
- **codellama** - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞
- **mistral** - –±—ã—Å—Ç—Ä–∞—è, —Ö–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å

---

## üé¨ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

```powershell
# –° llama2
python -m ai_qa_pipeline.modules.code_generation.cli full requirements.txt --base-url https://www.saucedemo.com --llm ollama --model llama2 --output tests

# –° llama3 (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
python -m ai_qa_pipeline.modules.code_generation.cli full requirements.txt --base-url https://www.saucedemo.com --llm ollama --model llama3 --output tests

# –° codellama
python -m ai_qa_pipeline.modules.code_generation.cli full requirements.txt --base-url https://www.saucedemo.com --llm ollama --model codellama --output tests

# –° mistral
python -m ai_qa_pipeline.modules.code_generation.cli full requirements.txt --base-url https://www.saucedemo.com --llm ollama --model mistral --output tests
```

---

## üîß –í—Å–µ —ç—Ç–∞–ø—ã —Å Ollama

### Stage 2: Test Generation

```powershell
python -m ai_qa_pipeline.modules.test_generation.cli requirements.txt -f -o scenarios.json --llm ollama --model llama2
```

### Stage 5-6: AI Code Review

```powershell
python -m ai_qa_pipeline.modules.code_review.cli ai-review generated_tests --llm ollama --model llama2 --format markdown -o review.md
```

### Stage 9: Log Analysis

```powershell
python -m ai_qa_pipeline.modules.log_analysis.cli results.json -o analysis.md --llm ollama --model llama2
```

### Stage 10: Bug Reports

```powershell
python -m ai_qa_pipeline.modules.bug_reporting.cli results.json -o bugs --format markdown --llm ollama --model llama2
```

---

## ‚ö†Ô∏è –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è

### 1. –°–∫–æ—Ä–æ—Å—Ç—å
Ollama —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –≤–∞—à–µ–º –∫–æ–º–ø—å—é—Ç–µ—Ä–µ –∏ –º–µ–¥–ª–µ–Ω–Ω–µ–µ –æ–±–ª–∞—á–Ω—ã—Ö API:
- **–ì–µ–Ω–µ—Ä–∞—Ü–∏—è 1 —Ç–µ—Å—Ç–∞:** 1-3 –º–∏–Ω—É—Ç—ã (vs 10 —Å–µ–∫—É–Ω–¥ —Å GPT-4)
- **Code review:** 2-5 –º–∏–Ω—É—Ç (vs 30 —Å–µ–∫—É–Ω–¥ —Å GPT-4)

### 2. –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∂–µ–ª–µ–∑—É
–î–ª—è –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã –Ω—É–∂–Ω–æ:
- **RAM:** –º–∏–Ω–∏–º—É–º 8GB, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 16GB
- **–î–∏—Å–∫:** ~10GB —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞
- **CPU:** —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä (–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ —Å AVX2)

### 3. –ö–∞—á–µ—Å—Ç–≤–æ
- –ò–Ω–æ–≥–¥–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –º–µ–Ω–µ–µ —Ç–æ—á–Ω—ã–π –∫–æ–¥
- –ú–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è —Ä—É—á–Ω–∞—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞
- –ù–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –±–∞–∑–æ–≤—ã—Ö —Ç–µ—Å—Ç–æ–≤ –≤–ø–æ–ª–Ω–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ!

---

## üêõ Troubleshooting

### –ü—Ä–æ–±–ª–µ–º–∞: "ollama: command not found"

```powershell
# –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ PowerShell
# –ò–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ Ollama —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω:
Get-Command ollama

# –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–æ - –ø–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Ollama
```

### –ü—Ä–æ–±–ª–µ–º–∞: "connection refused"

```powershell
# –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω
# –û—Ç–∫—Ä–æ–π—Ç–µ –Ω–æ–≤–æ–µ –æ–∫–Ω–æ PowerShell:
ollama serve

# –û—Å—Ç–∞–≤—å—Ç–µ —ç—Ç–æ –æ–∫–Ω–æ –æ—Ç–∫—Ä—ã—Ç—ã–º –∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥–æ–µ –¥–ª—è –∫–æ–º–∞–Ω–¥
```

### –ü—Ä–æ–±–ª–µ–º–∞: –ú–µ–¥–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞

```powershell
# 1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—å—à—É—é –º–æ–¥–µ–ª—å
ollama pull llama2:7b  # –≤–º–µ—Å—Ç–æ llama2:13b

# 2. –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ mistral (–±—ã—Å—Ç—Ä–µ–µ)
ollama pull mistral

# –ó–∞—Ç–µ–º:
python -m ai_qa_pipeline.modules.code_generation.cli full requirements.txt --base-url https://www.saucedemo.com --llm ollama --model mistral --output tests
```

### –ü—Ä–æ–±–ª–µ–º–∞: Out of memory

```powershell
# –ó–∞–∫—Ä–æ–π—Ç–µ –¥—Ä—É–≥–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã
# –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—å—à—É—é –º–æ–¥–µ–ª—å
# –ò–ª–∏ –¥–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ RAM
```

---

## üéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞

```powershell
# 1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Ollama
# –°–∫–∞—á–∞–π—Ç–µ —Å https://ollama.ai/download

# 2. –ó–∞–≥—Ä—É–∑–∏—Ç–µ llama3 (–ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ)
ollama pull llama3

# 3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ
ollama list

# 4. –°–æ–∑–¥–∞–π—Ç–µ –∞–ª–∏–∞—Å –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
# –î–æ–±–∞–≤—å—Ç–µ –≤ $PROFILE:
function Generate-Tests {
    param([string]$req = "requirements.txt", [string]$out = "generated_tests")
    python -m ai_qa_pipeline.modules.code_generation.cli full $req --base-url https://www.saucedemo.com --llm ollama --model llama3 --output $out
}

# –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ:
# Generate-Tests
```

---

## üí° –°–æ–≤–µ—Ç—ã –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é

### 1. –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫
–ü—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –≤ –ø–∞–º—è—Ç—å (~4GB), —ç—Ç–æ –∑–∞–Ω–∏–º–∞–µ—Ç –≤—Ä–µ–º—è. –ü–æ—Å–ª–µ–¥—É—é—â–∏–µ –∑–∞–ø—Ä–æ—Å—ã –±—É–¥—É—Ç –±—ã—Å—Ç—Ä–µ–µ.

### 2. –ü—Ä–æ—Å—Ç—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
–ü–∏—à–∏—Ç–µ –ø—Ä–æ—Å—Ç—ã–µ –∏ —á–µ—Ç–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:
```
Feature: Login
User can login with valid credentials
Username: standard_user
Password: secret_sauce
```

### 3. –ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
Ollama –º–æ–∂–µ—Ç –æ—à–∏–±–∞—Ç—å—Å—è —á–∞—â–µ —á–µ–º GPT-4. –í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥ –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º.

### 4. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Code Review
```powershell
python -m ai_qa_pipeline.modules.code_review.cli full generated_tests --llm ollama --model llama3 -o review.md
```

---

## üìä –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

–ù–∞ —Å—Ä–µ–¥–Ω–µ–º –ü–ö (i5, 16GB RAM):

| –û–ø–µ—Ä–∞—Ü–∏—è | –í—Ä–µ–º—è | Vs OpenAI |
|----------|-------|-----------|
| –ì–µ–Ω–µ—Ä–∞—Ü–∏—è 1 —Ç–µ—Å—Ç–∞ | 1-3 –º–∏–Ω | 10x –º–µ–¥–ª–µ–Ω–Ω–µ–µ |
| –ì–µ–Ω–µ—Ä–∞—Ü–∏—è 5 —Ç–µ—Å—Ç–æ–≤ | 5-15 –º–∏–Ω | 10x –º–µ–¥–ª–µ–Ω–Ω–µ–µ |
| Code review (1 —Ñ–∞–π–ª) | 2-5 –º–∏–Ω | 6x –º–µ–¥–ª–µ–Ω–Ω–µ–µ |
| Full pipeline | 10-20 –º–∏–Ω | 8x –º–µ–¥–ª–µ–Ω–Ω–µ–µ |

**–ù–æ –∑–∞—Ç–æ –±–µ—Å–ø–ª–∞—Ç–Ω–æ! üÜì**

---

## ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏

```powershell
# 1. Ollama —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω?
ollama --version

# 2. –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞?
ollama list

# 3. –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
ollama run llama2 "Write a simple Python function that adds two numbers"

# –ï—Å–ª–∏ –≤—ã–≤–µ–ª –∫–æ–¥ - –≤—Å–µ —Ä–∞–±–æ—Ç–∞–µ—Ç!
```

---

## üéì –î–ª—è –∑–∞—â–∏—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞

–ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ Ollama –Ω–∞ –∑–∞—â–∏—Ç–µ:

**–ü–ª—é—Å—ã:**
- ‚úÖ –ù–µ –Ω—É–∂–µ–Ω –∏–Ω—Ç–µ—Ä–Ω–µ—Ç (–µ—Å–ª–∏ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞)
- ‚úÖ –ë–µ—Å–ø–ª–∞—Ç–Ω–æ
- ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç –æ—Ñ–ª–∞–π–Ω

**–ú–∏–Ω—É—Å—ã:**
- ‚ùå –ú–µ–¥–ª–µ–Ω–Ω–µ–µ (10-20 –º–∏–Ω—É—Ç –≤–º–µ—Å—Ç–æ 2-3)
- ‚ùå –ö–∞—á–µ—Å—Ç–≤–æ —á—É—Ç—å –Ω–∏–∂–µ
- ‚ùå –ù—É–∂–µ–Ω –º–æ—â–Ω—ã–π –ü–ö

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:**
- –ó–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å –∑–∞—Ä–∞–Ω–µ–µ
- –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ —Ç–µ—Å—Ç—ã –¥–æ –∑–∞—â–∏—Ç—ã
- –ù–∞ –∑–∞—â–∏—Ç–µ –ø–æ–∫–∞–∂–∏—Ç–µ —É–∂–µ –≥–æ—Ç–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
- –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ OpenAI (–±—ã—Å—Ç—Ä–µ–µ –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–µ–µ)

---

## üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É OpenAI –∏ Ollama

```powershell
# OpenAI (–±—ã—Å—Ç—Ä–æ, –ø–ª–∞—Ç–Ω–æ, —Ç—Ä–µ–±—É–µ—Ç .env)
python -m ai_qa_pipeline.modules.code_generation.cli full requirements.txt --base-url https://www.saucedemo.com --llm openai --output tests

# Ollama (–º–µ–¥–ª–µ–Ω–Ω–æ, –±–µ—Å–ø–ª–∞—Ç–Ω–æ, –ª–æ–∫–∞–ª—å–Ω–æ)
python -m ai_qa_pipeline.modules.code_generation.cli full requirements.txt --base-url https://www.saucedemo.com --llm ollama --model llama3 --output tests
```

---

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

- **Ollama GitHub:** https://github.com/ollama/ollama
- **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:** https://github.com/ollama/ollama/blob/main/docs/README.md
- **–°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π:** https://ollama.ai/library
- **Community:** https://discord.gg/ollama

---

**–¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å AI-Driven QA Pipeline –±–µ—Å–ø–ª–∞—Ç–Ω–æ! ü¶ôüÜì**
